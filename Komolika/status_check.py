#!/usr/bin/env python3
"""
Status check script for the image caption generation project
"""

import os
import sys
from pickle import load

def check_file_exists(filepath, description):
    """Check if a file exists and print status"""
    if os.path.exists(filepath):
        size = os.path.getsize(filepath)
        size_mb = size / (1024 * 1024)
        print(f"‚úÖ {description}: {filepath} ({size_mb:.1f} MB)")
        return True
    else:
        print(f"‚ùå {description}: {filepath} (NOT FOUND)")
        return False

def check_directory_contents(dirpath, description):
    """Check directory contents"""
    if os.path.exists(dirpath):
        files = os.listdir(dirpath)
        print(f"‚úÖ {description}: {dirpath} ({len(files)} files)")
        return True
    else:
        print(f"‚ùå {description}: {dirpath} (NOT FOUND)")
        return False

def main():
    print("üîç IMAGE CAPTION GENERATION PROJECT STATUS CHECK")
    print("=" * 60)
    
    # Check trained model files
    print("\nüìÅ TRAINED MODEL FILES:")
    model_exists = check_file_exists("models/model_simple.h5", "Trained Model")
    tokenizer_exists = check_file_exists("models/tokenizer_simple.pkl", "Tokenizer")
    
    # Check dataset files
    print("\nüìÅ DATASET FILES:")
    check_file_exists("descriptions.txt", "Image Descriptions")
    check_file_exists("features.p", "Pre-extracted Features")
    check_directory_contents("Flickr8k_Dataset", "Image Dataset")
    check_directory_contents("Flickr8k_text", "Text Files")
    
    # Check script files
    print("\nüìÅ SCRIPT FILES:")
    check_file_exists("train_simple.py", "Training Script")
    check_file_exists("test_simple.py", "Test Script")
    check_file_exists("demo_simple.py", "Demo Script")
    
    # Check if model is ready to use
    print("\nüéØ MODEL STATUS:")
    if model_exists and tokenizer_exists:
        print("‚úÖ Model is ready for inference!")
        
        # Try to load tokenizer to get vocab info
        try:
            tokenizer = load(open("models/tokenizer_simple.pkl", "rb"))
            vocab_size = len(tokenizer.word_index) + 1
            print(f"‚úÖ Vocabulary size: {vocab_size:,} words")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not load tokenizer details: {e}")
        
        print("\nüöÄ READY TO USE:")
        print("   python test_simple.py --image path/to/your/image.jpg")
        print("   python demo_simple.py")
        
    else:
        print("‚ùå Model not ready. Please run training first:")
        print("   python train_simple.py")
    
    # Check environment
    print("\nüîß ENVIRONMENT:")
    try:
        import tensorflow as tf
        print(f"‚úÖ TensorFlow: {tf.__version__}")
    except ImportError:
        print("‚ùå TensorFlow not available")
    
    try:
        import numpy as np
        print(f"‚úÖ NumPy: {np.__version__}")
    except ImportError:
        print("‚ùå NumPy not available")
    
    try:
        from PIL import Image
        print("‚úÖ PIL (Pillow) available")
    except ImportError:
        print("‚ùå PIL (Pillow) not available")
    
    # Summary
    print("\n" + "=" * 60)
    if model_exists and tokenizer_exists:
        print("üéâ PROJECT STATUS: READY FOR INFERENCE!")
        print("üìù See TRAINING_SUMMARY.md for detailed results")
    else:
        print("‚ö†Ô∏è  PROJECT STATUS: NEEDS TRAINING")
        print("üìù Run 'python train_simple.py' to train the model")
    
    print("=" * 60)

if __name__ == '__main__':
    main()
